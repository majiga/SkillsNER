{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM + Character-level-embedding + CRF\n",
    "\n",
    "### Running on the small size data to prepare the training dataset\n",
    "\n",
    "https://www.depends-on-the-definition.com/lstm-with-char-embeddings-for-ner/\n",
    "\n",
    "Enhancing sequence tagging: Bidirectional LSTMs With Character Embeddings For Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33578\n",
      "Num words in training set =  26852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob, os, csv, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# AUTO-LABELLED DATA SET = TRAIN SET + VALIDATION SET\n",
    "filename = r\"C:\\Users\\20230326\\1-2 OzROCK\\Files\\autolabelled_smallsize_dictionary_labelled.txt\"\n",
    "\n",
    "#filename = r\"C:\\Users\\20230326\\wamex\\data\\OzROCK_Labeled_Geological_Dataset.txt\"  # 480 files\n",
    "#data = pd.read_csv(filename, header = None, delimiter=\" \", na_values=['\\n'], quoting=csv.QUOTE_NONE, encoding='latin1', skip_blank_lines=True)\n",
    "#print(data.info())\n",
    "#print(data.head(10))\n",
    "\n",
    "#data = dataframes.where((pd.notnull(dataframes)), None)\n",
    "#data = data.fillna('')\n",
    "#data = data.replace(np.nan, '', regex=True)\n",
    "\n",
    "words = []\n",
    "tags = []\n",
    "train_sentences = []\n",
    "\n",
    "with open(filename, 'r') as file :\n",
    "    currSentence = []\n",
    "    lines = []\n",
    "    for line in file:\n",
    "        cols = line.split(\" \")\n",
    "        if line.strip() == '':\n",
    "            # Reset sentence            \n",
    "            train_sentences.append(currSentence)\n",
    "            currSentence = []\n",
    "        elif len(cols) > 2:\n",
    "            print(line)\n",
    "        else:\n",
    "            currSentence.append([cols[0].strip(), cols[1].strip()])\n",
    "            words.append(cols[0].strip())\n",
    "            tags.append(cols[1].strip())\n",
    "print(len(train_sentences)) # 18589; 160,343\n",
    "\n",
    "train_words = list(set(words))\n",
    "print('Num words in training set = ', len(train_words))\n",
    "\n",
    "train_sent_lengths = [len(s) for s in train_sentences]\n",
    "\n",
    "plt.hist(train_sent_lengths, density=1, bins=1000) # x value is bins\n",
    "plt.axis([0, 140, 0, 0.1])  # xmin,xmax,ymin,ymax\n",
    "plt.xlabel('Sentence Length')\n",
    "plt.ylabel('Percentage of sentences')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797\n",
      "Num words in training + test sets =  5582\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TEST DATA - manually annotated\n",
    "test_filename = r\"C:\\Users\\20230326\\1-2 OzROCK\\Files\\TestSet_March03.txt\" # TestSet_March02\n",
    "filename_result = r\"C:\\Users\\20230326\\1-2 OzROCK\\Files\\TestSet_trueTag_modelTag.txt\"\n",
    "\n",
    "#test_data = pd.read_csv(filename, header = None, delimiter=\" \", na_values=['\\n'], quoting=csv.QUOTE_NONE, encoding='latin1', skip_blank_lines=True)\n",
    "#print(test_data.info())\n",
    "#print(test_data.head(10))\n",
    "words = []\n",
    "test_sentences = []\n",
    "with open(test_filename, 'r') as file :\n",
    "    currSentence = []\n",
    "    lines = []\n",
    "    for line in file:\n",
    "        cols = line.split(\" \")\n",
    "        if line.strip() == '':\n",
    "            # Reset sentence            \n",
    "            test_sentences.append(currSentence)\n",
    "            currSentence = []\n",
    "        elif len(cols) > 2:\n",
    "            print(line)\n",
    "        else :\n",
    "            currSentence.append([cols[0].strip(), cols[1].strip()])            \n",
    "            words.append(cols[0].strip())\n",
    "                \n",
    "print(len(test_sentences)) # 18589; 160,343\n",
    "\n",
    "test_words = list(set(words))\n",
    "print('Num words in training + test sets = ', len(test_words))\n",
    "\n",
    "test_sent_lengths = [len(s) for s in test_sentences]\n",
    "\n",
    "plt.hist(test_sent_lengths, density=1, bins=1000) # x value is bins\n",
    "plt.axis([0, 140, 0, 0.1])  # xmin,xmax,ymin,ymax\n",
    "plt.xlabel('Sentence Length')\n",
    "plt.ylabel('Percentage of sentences')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in all data:  29050\n",
      "\n",
      "Number of unique tags:  13\n",
      "['B-STRAT', 'B-ORE_DEPOSIT', 'O', 'B-ROCK', 'B-TIMESCALE', 'I-LOCATION', 'I-STRAT', 'B-LOCATION', 'I-TIMESCALE', 'I-ORE_DEPOSIT', 'I-ROCK', 'I-MINERAL', 'B-MINERAL']\n",
      "29050\n",
      "['since', 'trillbar_gradientenhanced_tmi_1vd.ecw', 'textu', 'muhling', '1,126', 'i12326', 'observations', 'fingernail', 'jpeg', 'c15']\n"
     ]
    }
   ],
   "source": [
    "# Word dictionary\n",
    "words = train_words + test_words\n",
    "words = list(set(words))\n",
    "words.append(\"ENDPAD\")\n",
    "\n",
    "n_words = len(words) # unique words\n",
    "print(\"Number of unique words in all data: \", n_words)\n",
    "\n",
    "tags = list(set(tags))\n",
    "n_tags = len(tags)\n",
    "print(\"\\nNumber of unique tags: \", n_tags)\n",
    "print(tags)\n",
    "\n",
    "print(len(words))\n",
    "print(words[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To encode the character-level information, we will use character embeddings and a LSTM to encode every word to an vector.\n",
    "We can use basically everything that produces a single vector for a sequence of characters that represent a word. You can also use a max-pooling architecture or a CNN or whatever works.\n",
    "Then we feed the vector to another LSTM together with the learned word embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5079\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Create dictionaries of words and tags.\n",
    "word2idx = {w: i + 4 for i, w in enumerate(words)}\n",
    "word2idx[\"UNK\"] = 1\n",
    "word2idx[\"PAD\"] = 0\n",
    "word2idx[\"null\"] = 2\n",
    "word2idx[\"nan\"] = 3\n",
    "\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "tag2idx = {t: i + 1 for i, t in enumerate(tags)}\n",
    "tag2idx[\"PAD\"] = 0\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "\n",
    "print(word2idx[\"gold\"]) # id=3818\n",
    "print(tag2idx[\"B-ROCK\"]) # id = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(word2idx[\"null\"]) # id=3818"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num words =  29053\n"
     ]
    }
   ],
   "source": [
    "max_len = 80 # length of each sentence\n",
    "\n",
    "#print(sentences[1])\n",
    "print('Num words = ', len(word2idx))\n",
    "\n",
    "X_word = [[word2idx[w[0]] for w in s] for s in train_sentences]\n",
    "#X_word = []\n",
    "#for s in sentences:\n",
    "#    for w in s:\n",
    "#        try:\n",
    "#            a = [word2idx[w[0]] for w in s]\n",
    "#            X_word.append(a)\n",
    "#        except KeyError as err:\n",
    "#            print('\\nException: ', sys.exc_info()[0], err, '\\n',\n",
    "#                  s, '\\n', w, a)\n",
    "#print(X_word[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\20230326\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\20230326\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\20230326\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\20230326\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\20230326\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\20230326\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Map the senctences to a sequence of numbers and then pad the sequence\n",
    "# we increased the index of the words by one to use zero as a padding value.\n",
    "# This is done because we want to use the mask_zeor parameter of the embedding layer to ignore inputs with value zero\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Pad the sentences\n",
    "X_word = pad_sequences(maxlen=max_len, sequences=X_word, value=word2idx[\"PAD\"], padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "since\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['since',\n",
       " 'trillbar_gradientenhanced_tmi_1vd.ecw',\n",
       " 'textu',\n",
       " 'muhling',\n",
       " '1,126',\n",
       " 'i12326',\n",
       " 'observations',\n",
       " 'fingernail',\n",
       " 'jpeg',\n",
       " 'c15']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(words[0])\n",
    "#words[0] = 'NaN'\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "word_values = []\n",
    "for w in words:\n",
    "    print(w)\n",
    "    if type(w) == str:\n",
    "        word_values.append(w)\n",
    "\n",
    "print(len(word_values))\n",
    "chars = set([w_i for w in word_values for w_i in w])\n",
    "n_chars = len(chars)\n",
    "print(n_chars)\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# Generate a dictionary for the characters we want to use and create the sequence of characters for every token,\n",
    "# set to 10.\n",
    "# We could also use longer or shorter sequences. \n",
    "# We could even use two sequences, one with the five first characters and one with the five last chars\n",
    "max_len_char = 30 # character length\n",
    "print(max_len_char)\n",
    "\n",
    "# tags = list(set(data[\"Tag\"].values))\n",
    "#chars = set([w_i for w in words for w_i in w])\n",
    "#n_chars = len(chars)\n",
    "#print(n_chars)\n",
    "#print(chars)\n",
    "\n",
    "import string\n",
    "chars = [s for s in string.printable]\n",
    "n_chars = len(chars)\n",
    "print(n_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2idx = {c: i + 2 for i, c in enumerate(chars)}\n",
    "char2idx[\"PAD\"] = 0\n",
    "char2idx[\"UNK\"] = 1\n",
    "len(char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_char = []\n",
    "for sentence in train_sentences:\n",
    "    sent_seq = []\n",
    "    for i in range(max_len):\n",
    "        word_seq = []\n",
    "        for j in range(max_len_char):\n",
    "            try:\n",
    "                word_seq.append(char2idx.get(sentence[i][0][j]))\n",
    "            except:\n",
    "                word_seq.append(char2idx.get(\"PAD\"))\n",
    "        sent_seq.append(word_seq)\n",
    "    X_char.append(np.array(sent_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 8, 3, 3, 3, 3, 3, 3, 3, 4, 11, 3, 3, 4, 11, 3, 3, 3, 3, 4, 3]\n",
      "[ 3  8  3  3  3  3  3  3  3  4 11  3  3  4 11  3  3  3  3  4  3  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "# Map tags to a sequence numbers and the pad\n",
    "y = [[tag2idx[w[1]] for w in s] for s in train_sentences]\n",
    "print(y[0])\n",
    "\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, value=tag2idx[\"PAD\"], padding='post', truncating='post')\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(len(X_char[5]))\n",
    "print(X_char[5].shape)\n",
    "print(X_char[5][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split in train and test set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_word_tr, X_word_te, y_tr, y_te = train_test_split(X_word, y, test_size=0.2, random_state=45)\n",
    "X_char_tr, X_char_te, _, _ = train_test_split(X_char, y, test_size=0.2, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26862, 80)\n",
      "(6716, 80)\n",
      "26862\n",
      "6716\n",
      "26862\n",
      "6716\n"
     ]
    }
   ],
   "source": [
    "print(X_word_tr.shape)\n",
    "print(X_word_te.shape)\n",
    "\n",
    "print(len(X_char_tr))\n",
    "print(len(X_char_te))\n",
    "\n",
    "print(len(y_tr))\n",
    "print(len(y_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the character embedding model\n",
    "Trick is to wrap the parts that should be applied to the characters in a TimeDistributed layer to apply the same layers to every character sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\20230326\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\20230326\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Conv1D\n",
    "from keras.layers import Bidirectional, concatenate, SpatialDropout1D, GlobalMaxPooling1D\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# input and embedding for words\n",
    "word_in = Input(shape=(max_len,))\n",
    "emb_word = Embedding(input_dim=n_words + 4, output_dim=64, input_length=max_len, mask_zero=True)(word_in)\n",
    "\n",
    "# input and embeddings for characters\n",
    "char_in = Input(shape=(max_len, max_len_char,))\n",
    "emb_char = TimeDistributed(Embedding(input_dim=n_chars + 2, output_dim=30, input_length=max_len_char, mask_zero=True))(char_in)\n",
    "\n",
    "# character LSTM to get word encodings by characters\n",
    "char_enc = TimeDistributed(LSTM(units=100, return_sequences=False, recurrent_dropout=0.5))(emb_char)\n",
    "\n",
    "# main LSTM\n",
    "x = concatenate([emb_word, char_enc])\n",
    "x = SpatialDropout1D(0.3)(x)\n",
    "\n",
    "main_lstm = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.5))(x)\n",
    "\n",
    "main_dense = TimeDistributed(Dense(100, activation=\"relu\"))(main_lstm)  # a dense layer as suggested by neuralNer\n",
    "\n",
    "out = TimeDistributed(Dense(n_tags + 1, activation=\"softmax\"))(main_dense)\n",
    "\n",
    "model = Model([word_in, char_in], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model: compile the model and look at the summary.\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
    "#model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 80, 30)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 80)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 80, 30, 30)   3060        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 80, 64)       1859456     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 80, 100)      52400       time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 80, 164)      0           embedding_1[0][0]                \n",
      "                                                                 time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 80, 164)      0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 80, 200)      212000      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 80, 100)      20100       bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 80, 14)       1414        time_distributed_3[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 2,148,430\n",
      "Trainable params: 2,148,430\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "plot_model(model, to_file='model2_WL_CL_BiLSTM.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\20230326\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 21489 samples, validate on 5373 samples\n",
      "Epoch 1/10\n",
      " - 319s - loss: 0.2771 - val_loss: 0.0757\n",
      "Epoch 2/10\n",
      " - 320s - loss: 0.0530 - val_loss: 0.0337\n",
      "Epoch 3/10\n",
      " - 313s - loss: 0.0280 - val_loss: 0.0241\n",
      "Epoch 4/10\n",
      " - 313s - loss: 0.0186 - val_loss: 0.0189\n",
      "Epoch 5/10\n",
      " - 317s - loss: 0.0141 - val_loss: 0.0175\n",
      "Epoch 6/10\n",
      " - 317s - loss: 0.0109 - val_loss: 0.0173\n",
      "Epoch 7/10\n",
      " - 318s - loss: 0.0090 - val_loss: 0.0167\n",
      "Epoch 8/10\n",
      " - 320s - loss: 0.0072 - val_loss: 0.0169\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-776cc9fb9c00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                      np.array(X_char_tr).reshape((len(X_char_tr), max_len, max_len_char))],\n\u001b[0;32m      7\u001b[0m                     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                     batch_size=32, epochs=10, validation_split=0.2, verbose=2)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#history = model.fit([X_word_tr,\n",
    "#                     np.array(X_char_tr).reshape((len(X_char_tr), max_len, max_len_char))],\n",
    "#                    np.array(y_tr).reshape(len(y_tr), max_len, 1),\n",
    "#                    batch_size=32, epochs=100, validation_split=0.1, verbose=1)\n",
    "history = model.fit([X_word_tr,\n",
    "                     np.array(X_char_tr).reshape((len(X_char_tr), max_len, max_len_char))],\n",
    "                    np.array(y_tr).reshape(len(y_tr), max_len, 1),\n",
    "                    batch_size=32, epochs=10, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(hist[\"loss\"])\n",
    "plt.plot(hist[\"val_loss\"])\n",
    "\n",
    "#plt.figure(figsize=(5,5))\n",
    "#plt.plot(hist[\"acc\"])\n",
    "#plt.plot(hist[\"val_acc\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "from keras.models import load_model\n",
    "\n",
    "model.save(r\"C:/Users/20230326/wamex/data/2020_model_WL_CL_BiLSTM_Small.h5\")  # creates a HDF5 file 'my_model.h5'\n",
    "#del model  # deletes the existing model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TEST this\n",
    "# returns a compiled model, identical to the previous one\n",
    "model_loaded = load_model(r\"C:/Users/20230326/wamex/data/2020_model_WL_CL_BiLSTM_Small.h5\")\n",
    "y_pred = model_loaded.predict([X_word_te,\n",
    "                        np.array(X_char_te).reshape((len(X_char_te), max_len, max_len_char))])\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3386"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict([X_word_te,\n",
    "                        np.array(X_char_te).reshape((len(X_char_te), max_len, max_len_char))])\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(i):\n",
    "    p = np.argmax(y_pred[i], axis=-1)\n",
    "    print(\"{:15}|{:15}|{}\".format(\"Word\", \"Truth\", \"Predicted\"))\n",
    "    print(40 * \"=\")\n",
    "\n",
    "    for w, t, pred in zip(X_word_te[i], y_te[i], p):\n",
    "        if w != 0:\n",
    "            print(\"{:15} {:15} {}\".format(idx2word[w], idx2tag[t], idx2tag[pred]))        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#for i in range(0, len(y_pred)):\n",
    "for i in range(0, 10):\n",
    "    print_prediction(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred) # Number of sentences in prediction / test set\n",
    "\n",
    "def get_results(i):\n",
    "    words_value = []\n",
    "    tags_true = []\n",
    "    tags_pred = []\n",
    "    p = np.argmax(y_pred[i], axis=-1)\n",
    "    #print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "    #print(30 * \"=\")\n",
    "\n",
    "    for w, t, pred in zip(X_word_te[i], y_te[i], p):\n",
    "        if w != 0:\n",
    "            #print(\"{:15}: {:5} {}\".format(idx2word[w], idx2tag[t], idx2tag[pred]))\n",
    "            words_value.append(idx2word[w])\n",
    "            tags_true.append(idx2tag[t])\n",
    "            tags_pred.append(idx2tag[pred])\n",
    "            \n",
    "    return words_value, tags_true, tags_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(0, len(y_pred)):\n",
    "words_tagged = []\n",
    "labels_true = []\n",
    "labels_predicted = []\n",
    "\n",
    "for i in range(0, len(y_pred)):\n",
    "    words_value, tags_true, tags_pred = get_results(i)\n",
    "    words_tagged.extend(words_value)\n",
    "    labels_true.extend(tags_true)\n",
    "    labels_predicted.extend(tags_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94198\n",
      "94198\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       ROCK     0.9629    0.9825    0.9726      2456\n",
      "  TIMESCALE     1.0000    1.0000    1.0000       261\n",
      "   LOCATION     0.9788    0.9883    0.9835      2055\n",
      "    MINERAL     0.9900    0.9895    0.9897      2093\n",
      "      STRAT     0.9227    0.9453    0.9338       530\n",
      "ORE_DEPOSIT     0.9545    0.9882    0.9711       255\n",
      "\n",
      "  micro avg     0.9726    0.9842    0.9784      7650\n",
      "  macro avg     0.9728    0.9842    0.9784      7650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "print(len(labels_true))\n",
    "#print(y_te[0])\n",
    "\n",
    "print(len(labels_predicted))\n",
    "#print(y_pred[0])\n",
    "\n",
    "#print(classification_report(labels_true, labels_predicted))\n",
    "print(classification_report(labels_true, labels_predicted, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MINERAL', 'O', 'B-MINERAL', 'B-ROCK', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MINERAL', 'O', 'B-MINERAL', 'B-ROCK', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(labels_true[:20])\n",
    "print(labels_predicted[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST SET\n",
    "## Manually annotated dataset for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 9 4 4 4 4 4 4 4 1 5 4 4 1 5 4 4 4 4 1 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n",
      "[ 4  4  4  4  4 11 10 10  4  4  4  4  4  4  4  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "Test set word shape =  (1799, 80)\n",
      "Test set character length =  1799\n",
      "Test set labels length =  1799\n"
     ]
    }
   ],
   "source": [
    "# Get the word ids for each sentence\n",
    "test_X_word = [[word2idx[w[0]] for w in s] for s in test_sentences]\n",
    "\n",
    "# Pad the sentences\n",
    "test_X_word = pad_sequences(maxlen=max_len, sequences=test_X_word, value=word2idx[\"PAD\"], padding='post', truncating='post')\n",
    "\n",
    "test_X_char = []\n",
    "for sentence in test_sentences:\n",
    "    sent_seq = []\n",
    "    for i in range(max_len):\n",
    "        word_seq = []\n",
    "        for j in range(max_len_char):\n",
    "            try:\n",
    "                word_seq.append(char2idx.get(sentence[i][0][j]))\n",
    "            except:\n",
    "                word_seq.append(char2idx.get(\"PAD\"))\n",
    "        sent_seq.append(word_seq)\n",
    "    test_X_char.append(np.array(sent_seq))\n",
    "    \n",
    "# Map tags to a sequence numbers and the pad\n",
    "test_y = [[tag2idx[w[1]] for w in s] for s in test_sentences]\n",
    "print(y[0])\n",
    "\n",
    "test_y = pad_sequences(maxlen=max_len, sequences=test_y, value=tag2idx[\"PAD\"], padding='post', truncating='post')\n",
    "print(test_y[0])\n",
    "\n",
    "print('Test set word shape = ', test_X_word.shape)\n",
    "print('Test set character length = ', len(test_X_char))\n",
    "print('Test set labels length = ', len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1799"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the labels on the manually created TEST SET\n",
    "test_y_pred = model.predict([test_X_word, np.array(test_X_char).reshape((len(test_X_char), max_len, max_len_char))])\n",
    "len(test_y_pred) # Number of sentences in prediction / test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48033\n",
      "48033\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "ORE_DEPOSIT     0.7072    0.5548    0.6218       283\n",
      "       ROCK     0.5596    0.5719    0.5657      1495\n",
      "  TIMESCALE     1.0000    0.0051    0.0102       196\n",
      "      STRAT     0.4206    0.0728    0.1241       618\n",
      "   LOCATION     0.0143    0.0011    0.0021       887\n",
      "    MINERAL     0.6577    0.7534    0.7023       969\n",
      "\n",
      "  micro avg     0.5889    0.4022    0.4780      4448\n",
      "  macro avg     0.4817    0.4022    0.4008      4448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_test_results(i):\n",
    "    words_value = []\n",
    "    tags_true = []\n",
    "    tags_pred = []\n",
    "    p = np.argmax(test_y_pred[i], axis=-1)\n",
    "    #print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "    #print(30 * \"=\")\n",
    "\n",
    "    for w, t, pred in zip(test_X_word[i], test_y[i], p):\n",
    "        if w != 0:\n",
    "            #print(\"{:15}: {:5} {}\".format(idx2word[w], idx2tag[t], idx2tag[pred]))\n",
    "            words_value.append(idx2word[w])\n",
    "            tags_true.append(idx2tag[t])\n",
    "            tags_pred.append(idx2tag[pred])\n",
    "            \n",
    "    return words_value, tags_true, tags_pred\n",
    "\n",
    "words_tagged = []\n",
    "labels_true = []\n",
    "labels_predicted = []\n",
    "\n",
    "for i in range(0, len(test_y_pred)):\n",
    "    words_value, tags_true, tags_pred = get_test_results(i)\n",
    "    words_tagged.extend(words_value)\n",
    "    labels_true.extend(tags_true)\n",
    "    labels_predicted.extend(tags_pred)\n",
    "    \n",
    "print(len(labels_true))\n",
    "#print(y_te[0])\n",
    "\n",
    "print(len(labels_predicted))\n",
    "#print(y_pred[0])\n",
    "\n",
    "#print(classification_report(labels_true, labels_predicted))\n",
    "print(classification_report(labels_true, labels_predicted, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(filename_result, 'w')\n",
    "f.write(\"Word, GroundTruth, Predicted\\n\")\n",
    "for i in range(0, len(test_y_pred)):    \n",
    "    p = np.argmax(test_y_pred[i], axis=-1)    \n",
    "    #print(40 * \"=\")\n",
    "\n",
    "    for w, t, pred in zip(test_X_word[i], test_y[i], p):\n",
    "        if w != 0:\n",
    "            #print(\"{:15} {:15} {}\".format(idx2word[w], idx2tag[t], idx2tag[pred]))  \n",
    "            f.write(idx2word[w] + ',' + idx2tag[t] + ',' + idx2tag[pred] + '\\n')\n",
    "f.close()\n",
    "#for i in range(0, 10):\n",
    "    #test_prediction(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction(i):    \n",
    "    p = np.argmax(test_y_pred[i], axis=-1)\n",
    "    print(\"{:15}|{:15}|{}\".format(\"Word\", \"GroundTruth\", \"Predicted\"))\n",
    "    print(40 * \"=\")\n",
    "\n",
    "    for w, t, pred in zip(test_X_word[i], test_y[i], p):\n",
    "        if w != 0:\n",
    "            print(\"{:15} {:15} {}\".format(idx2word[w], idx2tag[t], idx2tag[pred]))  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "c = 0\n",
    "for s in test_sentences:\n",
    "    for w in s:\n",
    "        c += 1\n",
    "        print(c, w, tag2idx[w[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#word2idx.keys()\n",
    "word2idx.values()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_char = []\n",
    "sentence = [‘Geographical’]\n",
    "max_len = 3\n",
    "max_len_char = 20\n",
    "\n",
    "for i in range(max_len):\n",
    "word_seq = []\n",
    "for j in range(max_len_char):\n",
    "try:\n",
    "word_seq.append(char2idx.get(sentence[i][j]))\n",
    "except:\n",
    "word_seq.append(char2idx.get(“PAD”))\n",
    "X_char.append(word_seq)\n",
    "\n",
    "X_char = [np.array(X_char)]\n",
    "X_word = [[word2idx[s] if s in word2idx.keys() else word2idx[‘UNK’] for s in sentence]]\n",
    "X_word = pad_sequences(maxlen=max_len, sequences=X_word, value=word2idx[“PAD”], padding=’post’, truncating=’post’)\n",
    "X_word = np.array(X_word)\n",
    "y_pred = model.predict([X_word, np.array(X_char).reshape((len(X_char), max_len, max_len_char))])\n",
    "p = np.argmax(y_pred[0], axis=-1)\n",
    "\n",
    "for pred in p:\n",
    "print(idx2tag[pred])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
